diff --git a/shardy/dialect/sdy/ir/parsers.cc b/shardy/dialect/sdy/ir/parsers.cc
index 746ce09..c20f17f 100644
--- a/shardy/dialect/sdy/ir/parsers.cc
+++ b/shardy/dialect/sdy/ir/parsers.cc
@@ -77,9 +77,15 @@ Attribute MeshAttr::parse(AsmParser& parser, Type type) {
       }
       return failure();
     };
+    if (parser.parseLSquare()) {
+      return MeshAttr();
+    }
     if (parser.parseCommaSeparatedList(AsmParser::Delimiter::None,
                                        parseElementFn) ||
-        parser.parseGreater()) {
+        parser.parseRSquare()) {
+      return MeshAttr();
+    }
+    if (parser.parseGreater()) {
       return MeshAttr();
     }
   }
diff --git a/shardy/dialect/sdy/ir/printers.cc b/shardy/dialect/sdy/ir/printers.cc
index 079e52c..1e1415a 100644
--- a/shardy/dialect/sdy/ir/printers.cc
+++ b/shardy/dialect/sdy/ir/printers.cc
@@ -35,8 +35,14 @@ void MeshAttr::print(AsmPrinter& printer) const {
   if (getDeviceId().has_value()) {
     printer << "device_ids=[" << *getDeviceId() << "]";
   } else {
+    if (!getAxes().empty()) {
+      printer << "[";
+    }
     llvm::interleaveComma(getAxes(), printer,
                           [&](MeshAxisAttr axis) { axis.print(printer); });
+    if (!getAxes().empty()) {
+      printer << "]";
+    }
   }
   printer << ">";
 }
diff --git a/shardy/dialect/sdy/ir/test/data_flow_edge_verification.mlir b/shardy/dialect/sdy/ir/test/data_flow_edge_verification.mlir
index b247d79..a870762 100644
--- a/shardy/dialect/sdy/ir/test/data_flow_edge_verification.mlir
+++ b/shardy/dialect/sdy/ir/test/data_flow_edge_verification.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -split-input-file -verify-diagnostics
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // Since DataFlowEdgeOp::verify has the same verification as any
 // TensorShardingAttr, there is no need to check different types of failures.
@@ -30,7 +30,7 @@ func.func @input_has_multiple_users(%arg0: tensor<32x96xf32>)
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @input_defined_by_sdy_op(%arg0: tensor<32x96xf32>)
     -> tensor<32x96xf32> {
diff --git a/shardy/dialect/sdy/ir/test/manual_computation_canonicalization.mlir b/shardy/dialect/sdy/ir/test/manual_computation_canonicalization.mlir
index fff44d9..b5a848e 100644
--- a/shardy/dialect/sdy/ir/test/manual_computation_canonicalization.mlir
+++ b/shardy/dialect/sdy/ir/test/manual_computation_canonicalization.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -canonicalize | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // CHECK-LABEL: func @unused_args
 func.func @unused_args(%arg0: tensor<8xf32>, %arg1: tensor<32x32xf32>, %arg2: tensor<16xf32>) -> tensor<32x32xf32> {
diff --git a/shardy/dialect/sdy/ir/test/manual_computation_parse_print.mlir b/shardy/dialect/sdy/ir/test/manual_computation_parse_print.mlir
index 472faed..9018dac 100644
--- a/shardy/dialect/sdy/ir/test/manual_computation_parse_print.mlir
+++ b/shardy/dialect/sdy/ir/test/manual_computation_parse_print.mlir
@@ -1,8 +1,8 @@
 // RUN: sdy_opt %s 2>&1 | FileCheck %s
 
 // CHECK: sdy.mesh
-sdy.mesh @meshA = <"a"=2, "b"=2>
-sdy.mesh @meshB = <"a"=4>
+sdy.mesh @meshA = <["a"=2, "b"=2]>
+sdy.mesh @meshB = <["a"=4]>
 
 // CHECK-LABEL: func @manual_computation_no_inputs_or_outputs
 func.func @manual_computation_no_inputs_or_outputs() {
diff --git a/shardy/dialect/sdy/ir/test/manual_computation_verification.mlir b/shardy/dialect/sdy/ir/test/manual_computation_verification.mlir
index a10e3fd..c74469a 100644
--- a/shardy/dialect/sdy/ir/test/manual_computation_verification.mlir
+++ b/shardy/dialect/sdy/ir/test/manual_computation_verification.mlir
@@ -1,7 +1,7 @@
 // RUN: sdy_opt %s -split-input-file -verify-diagnostics
 
-sdy.mesh @meshA = <"a"=2>
-sdy.mesh @meshB = <"a"=2>
+sdy.mesh @meshA = <["a"=2]>
+sdy.mesh @meshB = <["a"=2]>
 
 func.func @man_comp_different_meshes(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op result shardings can only refer to one mesh: @meshB vs @meshA}}
@@ -24,7 +24,7 @@ func.func @manual_computation_no_inputs_or_outputs_with_manual_axes() {
 
 // -----
 
-sdy.mesh @mesh = <"a"=4>
+sdy.mesh @mesh = <["a"=4]>
 
 func.func @man_comp_split_axes_sharding(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op operand sharding at index 0 cannot refer to the sub/split axes "a":(1)2 as the axis "a" is a manual axis}}
@@ -37,7 +37,7 @@ func.func @man_comp_split_axes_sharding(%arg0: tensor<16x32xf32>) -> tensor<16x3
 
 // -----
 
-sdy.mesh @mesh = <"a"=2, "b"=4>
+sdy.mesh @mesh = <["a"=2, "b"=4]>
 
 func.func @man_comp_split_axes_sharding_two_axes_sharding(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op operand sharding at index 0 cannot refer to the sub/split axes "b":(1)2 as the axis "b" is a manual axis}}
@@ -50,7 +50,7 @@ func.func @man_comp_split_axes_sharding_two_axes_sharding(%arg0: tensor<16x32xf3
 
 // -----
 
-sdy.mesh @mesh = <"a"=2, "b"=4>
+sdy.mesh @mesh = <["a"=2, "b"=4]>
 
 func.func @man_comp_split_axes_sharding_two_axes_replicated(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op operand sharding at index 0 cannot refer to the sub/split axes "b":(1)2 as the axis "b" is a manual axis}}
@@ -63,7 +63,7 @@ func.func @man_comp_split_axes_sharding_two_axes_replicated(%arg0: tensor<16x32x
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_more_arg_specs(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op operand shardings don't match number of values: 2 shardings vs 1 values}}
@@ -76,7 +76,7 @@ func.func @man_comp_more_arg_specs(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_less_arg_specs(%arg0: tensor<16x32xf32>, %arg1: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op operand shardings don't match number of values: 1 shardings vs 2 values}}
@@ -89,7 +89,7 @@ func.func @man_comp_less_arg_specs(%arg0: tensor<16x32xf32>, %arg1: tensor<16x32
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_more_result_specs(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op result shardings don't match number of values: 2 shardings vs 1 values}}
@@ -102,7 +102,7 @@ func.func @man_comp_more_result_specs(%arg0: tensor<16x32xf32>) -> tensor<16x32x
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_less_result_specs(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op result shardings don't match number of values: 1 shardings vs 2 values}}
@@ -115,7 +115,7 @@ func.func @man_comp_less_result_specs(%arg0: tensor<16x32xf32>) -> tensor<16x32x
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_operand_rank_mistmatch(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op operand - sharding doesn't match tensor rank: 3 != 2}}
@@ -128,7 +128,7 @@ func.func @man_comp_operand_rank_mistmatch(%arg0: tensor<16x32xf32>) -> tensor<1
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_result_rank_mistmatch(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{sharding doesn't match tensor rank: 1 != 2}}
@@ -141,7 +141,7 @@ func.func @man_comp_result_rank_mistmatch(%arg0: tensor<16x32xf32>) -> tensor<16
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_operand_shape_mismatch_replicated(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op operand shape, corresponding sharding, and region operand shape at index 0 must match. Expected local shape 'tensor<16x32xf32>', actual local shape 'tensor<8x32xf32>'}}
@@ -154,7 +154,7 @@ func.func @man_comp_operand_shape_mismatch_replicated(%arg0: tensor<16x32xf32>)
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_operand_shape_mismatch_sharded(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op operand shape, corresponding sharding, and region operand shape at index 0 must match. Expected local shape 'tensor<8x32xf32>', actual local shape 'tensor<16x32xf32>'}}
@@ -167,7 +167,7 @@ func.func @man_comp_operand_shape_mismatch_sharded(%arg0: tensor<16x32xf32>) ->
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_result_shape_mismatch_sharded(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op result shape, corresponding sharding, and region result shape at index 0 must match. Expected local shape 'tensor<8x32xf32>', actual local shape 'tensor<16x32xf32>'}}
@@ -180,7 +180,7 @@ func.func @man_comp_result_shape_mismatch_sharded(%arg0: tensor<16x32xf32>) -> t
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_results_number_mismatch(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{number of op results and region results must match. Op has 1 op results and 2 region results}}
@@ -193,7 +193,7 @@ func.func @man_comp_results_number_mismatch(%arg0: tensor<16x32xf32>) -> tensor<
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_operands_number_mismatch(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{number of op operands and region operands must match. Op has 1 op operands and 2 region operands}}
@@ -206,7 +206,7 @@ func.func @man_comp_operands_number_mismatch(%arg0: tensor<16x32xf32>) -> tensor
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @man_comp_free_variables(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-note @+1 {{required by region isolation constraints}}
@@ -220,7 +220,7 @@ func.func @man_comp_free_variables(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32
 
 // -----
 
-sdy.mesh @foo = <"a"=2, "b"=2>
+sdy.mesh @foo = <["a"=2, "b"=2]>
 
 func.func @manual_computation_nested_same_manual_axis(%arg0: tensor<16x32xf32>) -> tensor<8x32xf32> {
   // expected-note @+1  {{parent bounding this axis as manual}}
@@ -240,7 +240,7 @@ func.func @manual_computation_nested_same_manual_axis(%arg0: tensor<16x32xf32>)
 
 // -----
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 func.func @unused_manual_axis(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{op result sharding at index 0 must refer to all manual_axes: {"a", "b"}}}
@@ -253,7 +253,7 @@ func.func @unused_manual_axis(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
 
 // -----
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 func.func @unsorted_manual_axes(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   // expected-error @+1 {{manual axes are not ordered w.r.t. mesh}}
@@ -266,7 +266,7 @@ func.func @unsorted_manual_axes(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
 
 // -----
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 func.func @free_axes_before_manual_dim_sharding(%arg0: tensor<16x32xf32>) -> tensor<16x16xf32> {
   // expected-error @+1 {{op operand sharding at index 0 must have all manual axes come before free axes in its dimension sharding at index 1. Saw manual axis "b" after free axis "a"}}
diff --git a/shardy/dialect/sdy/ir/test/mesh_parse_print.mlir b/shardy/dialect/sdy/ir/test/mesh_parse_print.mlir
index 3a99357..3a9bff6 100644
--- a/shardy/dialect/sdy/ir/test/mesh_parse_print.mlir
+++ b/shardy/dialect/sdy/ir/test/mesh_parse_print.mlir
@@ -3,11 +3,11 @@
 // CHECK: sdy.mesh @mesh = <device_ids=[0]>
 sdy.mesh @mesh = <device_ids=[0]>
 
-// CHECK: sdy.mesh @mesh2 = <"a"=2>
-sdy.mesh @mesh2 = <"a"=2>
+// CHECK: sdy.mesh @mesh2 = <["a"=2]>
+sdy.mesh @mesh2 = <["a"=2]>
 
-// CHECK: sdy.mesh @mesh3 = <"a"=2, "b"=1>
-sdy.mesh @mesh3 = <"a"=2, "b"=1>
+// CHECK: sdy.mesh @mesh3 = <["a"=2, "b"=1]>
+sdy.mesh @mesh3 = <["a"=2, "b"=1]>
 
 // CHECK: sdy.mesh @mesh4 = <>
 sdy.mesh @mesh4 = <>
diff --git a/shardy/dialect/sdy/ir/test/mesh_verification.mlir b/shardy/dialect/sdy/ir/test/mesh_verification.mlir
index c86b985..c2bdb25 100644
--- a/shardy/dialect/sdy/ir/test/mesh_verification.mlir
+++ b/shardy/dialect/sdy/ir/test/mesh_verification.mlir
@@ -1,18 +1,17 @@
 // RUN: sdy_opt %s -split-input-file -verify-diagnostics
 
 // expected-error @+1 {{axis size must be at least 1, got: 0}}
-sdy.mesh @mesh = <"a"=2, "b"=0>
+sdy.mesh @mesh = <["a"=2, "b"=0]>
 
 // -----
 
 // expected-error @+1 {{duplicate axis name: "a"}}
-sdy.mesh @mesh = <"a"=2, "b"=2, "a"=4>
+sdy.mesh @mesh = <["a"=2, "b"=2, "a"=4]>
 
 // -----
 // expected-error @+1 {{device id must be non-negative, got: -1}}
 sdy.mesh @mesh = <device_ids=[-1]>
 
 // -----
-// expected-error @below {{custom op 'sdy.mesh' expected string}}
-// expected-error @below {{custom op 'sdy.mesh' failed to parse Sdy_MeshAxis parameter 'name' which is to be a `::llvm::StringRef`}}
-sdy.mesh @mesh = <"a"=2, "b"=2, device_ids=[2]>
+// expected-error @+1 {{expected '>'}}
+sdy.mesh @mesh = <["a"=2, "b"=2], device_ids=[2]>
diff --git a/shardy/dialect/sdy/ir/test/propagation_barrier_parse_print.mlir b/shardy/dialect/sdy/ir/test/propagation_barrier_parse_print.mlir
index c74afac..baa039e 100644
--- a/shardy/dialect/sdy/ir/test/propagation_barrier_parse_print.mlir
+++ b/shardy/dialect/sdy/ir/test/propagation_barrier_parse_print.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -- 2>&1 | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2,"b"=2>
+sdy.mesh @mesh = <["a"=2,"b"=2]>
 
 // CHECK-LABEL: func @backward
 func.func @backward(%arg0: tensor<8xf32>) -> tensor<8xf32> {
diff --git a/shardy/dialect/sdy/ir/test/reshard_canonicalization.mlir b/shardy/dialect/sdy/ir/test/reshard_canonicalization.mlir
index eea4875..2ece3d5 100644
--- a/shardy/dialect/sdy/ir/test/reshard_canonicalization.mlir
+++ b/shardy/dialect/sdy/ir/test/reshard_canonicalization.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -canonicalize | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 // CHECK-LABEL: func @reshard_of_reshard_no_other_uses
 // CHECK-NEXT: %0 = sdy.reshard %arg0 <@mesh, [{"a", ?}, {?}]>
diff --git a/shardy/dialect/sdy/ir/test/reshard_verification.mlir b/shardy/dialect/sdy/ir/test/reshard_verification.mlir
index 74a66cb..2201d8b 100644
--- a/shardy/dialect/sdy/ir/test/reshard_verification.mlir
+++ b/shardy/dialect/sdy/ir/test/reshard_verification.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -split-input-file -verify-diagnostics
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 // Since ReshardOp::verify has the same verification as any TensorShardingAttr,
 // there is no need to check different types of failures.
@@ -12,7 +12,7 @@ func.func @invalid_sharding(%arg0 : tensor<8xf32>) -> tensor<8xf32> {
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @constraint_sharding_inside_bound_manual_computation(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"a",?}, {?}]>] out_shardings=[<@mesh, [{"a",?}, {?}]>] manual_axes={"a"} (%arg1: tensor<8x32xf32>) { // expected-note  {{parent bounding this axis as manual}}
@@ -24,7 +24,7 @@ func.func @constraint_sharding_inside_bound_manual_computation(%arg0: tensor<16x
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @constraint_replication_inside_bound_manual_computation(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"a",?}, {?}]>] out_shardings=[<@mesh, [{"a",?}, {?}]>] manual_axes={"a"} (%arg1: tensor<8x32xf32>) { // expected-note  {{parent bounding this axis as manual}}
diff --git a/shardy/dialect/sdy/ir/test/sharding_constraint_verification.mlir b/shardy/dialect/sdy/ir/test/sharding_constraint_verification.mlir
index a2e2b13..22503e5 100644
--- a/shardy/dialect/sdy/ir/test/sharding_constraint_verification.mlir
+++ b/shardy/dialect/sdy/ir/test/sharding_constraint_verification.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -split-input-file -verify-diagnostics
 
-sdy.mesh @mesh = <"a"=2,"b"=2>
+sdy.mesh @mesh = <["a"=2,"b"=2]>
 
 // Since ShardingConstraintOp::verify has the same verification as any
 // TensorShardingAttr, there is no need to check different types of failures.
@@ -12,7 +12,7 @@ func.func @invalid_sharding(%arg0 : tensor<8xf32>) -> tensor<8xf32> {
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @constraint_sharding_inside_bound_manual_computation(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"a",?}, {?}]>] out_shardings=[<@mesh, [{"a",?}, {?}]>] manual_axes={"a"} (%arg1: tensor<8x32xf32>) { // expected-note  {{parent bounding this axis as manual}}
@@ -24,7 +24,7 @@ func.func @constraint_sharding_inside_bound_manual_computation(%arg0: tensor<16x
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @constraint_replication_inside_bound_manual_computation(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"a",?}, {?}]>] out_shardings=[<@mesh, [{"a",?}, {?}]>] manual_axes={"a"} (%arg1: tensor<8x32xf32>) { // expected-note  {{parent bounding this axis as manual}}
diff --git a/shardy/dialect/sdy/ir/test/tensor_sharding_parse_print.mlir b/shardy/dialect/sdy/ir/test/tensor_sharding_parse_print.mlir
index d2356b5..30466b8 100644
--- a/shardy/dialect/sdy/ir/test/tensor_sharding_parse_print.mlir
+++ b/shardy/dialect/sdy/ir/test/tensor_sharding_parse_print.mlir
@@ -1,10 +1,10 @@
 // RUN: sdy_opt %s 2>&1 | FileCheck %s
 
-// CHECK: sdy.mesh @foo = <"a"=2, "b"=4>
-sdy.mesh @foo = <"a"=2, "b"=4>
+// CHECK: sdy.mesh @foo = <["a"=2, "b"=4]>
+sdy.mesh @foo = <["a"=2, "b"=4]>
 
-// CHECK: sdy.mesh @bar = <"a"=4, "b"=2>
-sdy.mesh @bar = <"a"=4, "b"=2>
+// CHECK: sdy.mesh @bar = <["a"=4, "b"=2]>
+sdy.mesh @bar = <["a"=4, "b"=2]>
 
 // CHECK-LABEL: func @no_results
 func.func @no_results(%arg0 : tensor<8x8xf32>) -> tensor<8x8xf32> {
diff --git a/shardy/dialect/sdy/ir/test/tensor_sharding_parsing_failure.mlir b/shardy/dialect/sdy/ir/test/tensor_sharding_parsing_failure.mlir
index 22360d9..a1f34d4 100644
--- a/shardy/dialect/sdy/ir/test/tensor_sharding_parsing_failure.mlir
+++ b/shardy/dialect/sdy/ir/test/tensor_sharding_parsing_failure.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -split-input-file -verify-diagnostics
 
-sdy.mesh @foo = <"a"=2,"b"=4>
+sdy.mesh @foo = <["a"=2,"b"=4]>
 
 func.func @priority_without_numbers(%arg0 : tensor<8x8xf32>, %arg1 : tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error@+3 {{expecting priority in format 'p<number>', got: phigh}}
@@ -13,7 +13,7 @@ func.func @priority_without_numbers(%arg0 : tensor<8x8xf32>, %arg1 : tensor<8x8x
 
 // -----
 
-sdy.mesh @foo = <"a"=2,"b"=4>
+sdy.mesh @foo = <["a"=2,"b"=4]>
 
 func.func @priority_integer_overflow(%arg0 : tensor<8x8xf32>, %arg1 : tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error@+3 {{expecting integer priority, got: p9999999999999999999}}
@@ -25,7 +25,7 @@ func.func @priority_integer_overflow(%arg0 : tensor<8x8xf32>, %arg1 : tensor<8x8
 
 // -----
 
-sdy.mesh @foo = <"a"=2,"b"=4>
+sdy.mesh @foo = <["a"=2,"b"=4]>
 
 // expected-error@+2{{priorities with leading zeros are not allowed, got: p01}}
 // expected-error@+1{{failed to parse Sdy_TensorSharding parameter 'dim_shardings' which is to be a `::llvm::ArrayRef<DimensionShardingAttr>`}}
diff --git a/shardy/dialect/sdy/ir/test/tensor_sharding_verification.mlir b/shardy/dialect/sdy/ir/test/tensor_sharding_verification.mlir
index 540ce8d..ca6cd63 100644
--- a/shardy/dialect/sdy/ir/test/tensor_sharding_verification.mlir
+++ b/shardy/dialect/sdy/ir/test/tensor_sharding_verification.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -split-input-file -verify-diagnostics
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // expected-error @+1 {{'func.func' op arg 0 - non-shaped tensors can only have a sharding with rank 0 and no replicated axes}}
 func.func @token_sharding_rank_non_zero(%arg0: !stablehlo.token {sdy.sharding=#sdy.sharding<@mesh, [{}]>}) -> !stablehlo.token {
@@ -9,7 +9,7 @@ func.func @token_sharding_rank_non_zero(%arg0: !stablehlo.token {sdy.sharding=#s
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // expected-error @+1 {{'func.func' op arg 0 - non-shaped tensors can only have a sharding with rank 0 and no replicated axes}}
 func.func @token_sharding_with_replicated_axes(%arg0: !stablehlo.token {sdy.sharding=#sdy.sharding<@mesh, [], replicated={"a"}>}) -> !stablehlo.token {
@@ -18,7 +18,7 @@ func.func @token_sharding_with_replicated_axes(%arg0: !stablehlo.token {sdy.shar
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // expected-error @+1 {{'func.func' op arg 0 - only ranked tensors with a static shape can have a sharding}}
 func.func @unranked_tensor_with_sharding(%arg0: tensor<*xf32> {sdy.sharding=#sdy.sharding<@mesh, []>}) -> tensor<*xf32> {
@@ -27,7 +27,7 @@ func.func @unranked_tensor_with_sharding(%arg0: tensor<*xf32> {sdy.sharding=#sdy
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // expected-error @+1 {{'func.func' op arg 0 - only ranked tensors with a static shape can have a sharding}}
 func.func @dynamic_shaped_tensor_with_sharding(%arg0: tensor<*xf32> {sdy.sharding=#sdy.sharding<@mesh, [{}, {}]>}) -> tensor<?x?xf32> {
@@ -36,7 +36,7 @@ func.func @dynamic_shaped_tensor_with_sharding(%arg0: tensor<*xf32> {sdy.shardin
 
 // -----
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 func.func @dim_shardings_rank_mismatch(%arg0: tensor<8xf32>, %arg1: tensor<8xf32>) -> tensor<8xf32> {
   // expected-error @+1 {{op result - sharding doesn't match tensor rank: 2 != 1}}
@@ -46,7 +46,7 @@ func.func @dim_shardings_rank_mismatch(%arg0: tensor<8xf32>, %arg1: tensor<8xf32
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @op_with_unknown_mesh(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{op result - unknown mesh: @other_mesh}}
@@ -56,7 +56,7 @@ func.func @op_with_unknown_mesh(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>)
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // expected-error @+1 {{'func.func' op arg 0 - unknown mesh: @other_mesh}}
 func.func @func_arg_unknown_mesh(%arg0: tensor<8x8xf32> {sdy.sharding=#sdy.sharding<@other_mesh, [{}, {"a"}]>},
@@ -67,7 +67,7 @@ func.func @func_arg_unknown_mesh(%arg0: tensor<8x8xf32> {sdy.sharding=#sdy.shard
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // CHECK-LABEL: func @op_with_tensor_sharding_attr
 func.func @op_with_tensor_sharding_attr(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
@@ -78,7 +78,7 @@ func.func @op_with_tensor_sharding_attr(%arg0: tensor<8x8xf32>, %arg1: tensor<8x
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // expected-error @+1 {{'func.func' op arg 1 - should have a sharding attribute of type TensorShardingAttr}}
 func.func @func_arg_with_tensor_sharding_per_value_attr(
@@ -91,7 +91,7 @@ func.func @func_arg_with_tensor_sharding_per_value_attr(
 
 // -----
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 // CHECK-LABEL: func @num_shardings_does_not_match_num_results
 func.func @num_shardings_does_not_match_num_results(%arg0: tensor<2x64x13xf32>, %arg1: tensor<2x64x13xf32>) -> (tensor<2x13xf32>, tensor<2x13xf32>) {
@@ -112,8 +112,8 @@ func.func @num_shardings_does_not_match_num_results(%arg0: tensor<2x64x13xf32>,
 
 // -----
 
-sdy.mesh @mesh1 = <"a"=2>
-sdy.mesh @mesh2 = <"b"=2>
+sdy.mesh @mesh1 = <["a"=2]>
+sdy.mesh @mesh2 = <["b"=2]>
 
 // CHECK-LABEL: func @op_shardings_refers_to_multiples_meshes
 func.func @op_shardings_refers_to_multiples_meshes(%arg0: tensor<2x64x13xf32>, %arg1: tensor<2x64x13xf32>) -> (tensor<2x13xf32>, tensor<2x13xf32>) {
@@ -132,7 +132,7 @@ func.func @op_shardings_refers_to_multiples_meshes(%arg0: tensor<2x64x13xf32>, %
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // The purpose of this test is to check the error msg prefix for a func arg.
 // expected-error @+1 {{'func.func' op arg 0 - unknown axis name: "c"}}
@@ -145,7 +145,7 @@ func.func @func_arg_failure(%arg0: tensor<8x8xf32> {sdy.sharding=#sdy.sharding<@
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // The purpose of this test is to check the error msg prefix for a func result.
 // expected-error @+1 {{'func.func' op result 2 - unknown axis name: "c"}}
@@ -157,7 +157,7 @@ func.func @func_result_failure(%arg0: tensor<8x8xf32> {sdy.sharding=#sdy.shardin
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // The purpose of this test is to check the error msg prefix for a single-result
 // op.
@@ -169,7 +169,7 @@ func.func @single_result_op_failure(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf3
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // The purpose of this test is to check the error msg prefix for a multi-result
 // op.
@@ -189,7 +189,7 @@ func.func @multi_result_op_failure(%arg0: tensor<2x64x13xf32>, %arg1: tensor<2x6
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @unknown_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{unknown axis name: "c"}}
@@ -199,7 +199,7 @@ func.func @unknown_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tenso
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @unknown_replicated_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{unknown axis name: "c"}}
@@ -209,7 +209,7 @@ func.func @unknown_replicated_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @duplicate_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{duplicate axis ref: "a"}}
@@ -219,7 +219,7 @@ func.func @duplicate_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> ten
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @duplicate_replicated_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{duplicate axis ref: "a"}}
@@ -229,7 +229,7 @@ func.func @duplicate_replicated_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @duplicate_sharded_axis_same_dim(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{duplicate axis ref: "a"}}
@@ -239,7 +239,7 @@ func.func @duplicate_sharded_axis_same_dim(%arg0: tensor<8x8xf32>, %arg1: tensor
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @duplicate_sharded_axis_different_dims(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{duplicate axis ref: "a"}}
@@ -249,7 +249,7 @@ func.func @duplicate_sharded_axis_different_dims(%arg0: tensor<8x8xf32>, %arg1:
 
 // -----
 
-sdy.mesh @mesh = <"c"=2, "a"=2, "b"=2>
+sdy.mesh @mesh = <["c"=2, "a"=2, "b"=2]>
 
 func.func @unordered_replicated_axes(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{replicated axes are not ordered w.r.t. mesh}}
@@ -259,7 +259,7 @@ func.func @unordered_replicated_axes(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf
 
 // -----
 
-sdy.mesh @mesh = <"a"=2,"b"=4>
+sdy.mesh @mesh = <["a"=2,"b"=4]>
 
 func.func @empty_closed_dim_sharding_with_priority(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error@+1 {{dim 1 is empty and closed but has a priority}}
@@ -269,7 +269,7 @@ func.func @empty_closed_dim_sharding_with_priority(%arg0: tensor<8x8xf32>, %arg1
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @size_zero_dim_sharded(%arg0: tensor<8x0xf32>, %arg1: tensor<8x0xf32>) -> tensor<8x0xf32> {
   // expected-error @+1 {{dim 1 of size 0 is sharded}}
@@ -279,7 +279,7 @@ func.func @size_zero_dim_sharded(%arg0: tensor<8x0xf32>, %arg1: tensor<8x0xf32>)
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @unknown_sub_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{unknown axis name: "c"}}
@@ -289,7 +289,7 @@ func.func @unknown_sub_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> t
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @duplicate_sub_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{duplicate axis ref: "a":(2)2}}
@@ -299,7 +299,7 @@ func.func @duplicate_sub_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) ->
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @both_full_axis_and_sub_axis_used(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{both sub-axis and full-axis are used for axis name: "a"}}
@@ -309,7 +309,7 @@ func.func @both_full_axis_and_sub_axis_used(%arg0: tensor<8x8xf32>, %arg1: tenso
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @unordered_replicated_sub_axes(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{replicated axes are not ordered w.r.t. mesh}}
@@ -319,7 +319,7 @@ func.func @unordered_replicated_sub_axes(%arg0: tensor<8x8xf32>, %arg1: tensor<8
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @redundant_sub_axis_in_dim(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{two consecutive sub-axes can be merged: "a":(2)2, "a":(4)4}}
@@ -329,7 +329,7 @@ func.func @redundant_sub_axis_in_dim(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @redundant_replicated_sub_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{two consecutive sub-axes can be merged: "a":(2)2, "a":(4)4}}
@@ -339,7 +339,7 @@ func.func @redundant_replicated_sub_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @sub_axis_non_positive_pre_size(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{sub-axis pre-size must be at least 1: "a":(-1)2}}
@@ -349,7 +349,7 @@ func.func @sub_axis_non_positive_pre_size(%arg0: tensor<8x8xf32>, %arg1: tensor<
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @sub_axis_size_one(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{sub-axis sizes must be greater than 1: "a":(2)1}}
@@ -359,7 +359,7 @@ func.func @sub_axis_size_one(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) ->
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @sub_axis_pre_size_does_not_divide(%arg0: tensor<6x6xf32>, %arg1: tensor<6x6xf32>) -> tensor<6x6xf32> {
   // expected-error @+1 {{sub-axis next pre-size 6 doesn't divide the size of the full axis 8: "a":(3)2}}
@@ -369,7 +369,7 @@ func.func @sub_axis_pre_size_does_not_divide(%arg0: tensor<6x6xf32>, %arg1: tens
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @sub_axis_size_does_not_divide(%arg0: tensor<6x6xf32>, %arg1: tensor<6x6xf32>) -> tensor<6x6xf32> {
   // expected-error @+1 {{sub-axis next pre-size 6 doesn't divide the size of the full axis 8: "a":(2)3}}
@@ -379,7 +379,7 @@ func.func @sub_axis_size_does_not_divide(%arg0: tensor<6x6xf32>, %arg1: tensor<6
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @sub_axis_next_pre_size_beyond_axis(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{sub-axis next pre-size 16 doesn't divide the size of the full axis 8: "a":(4)4}}
@@ -389,7 +389,7 @@ func.func @sub_axis_next_pre_size_beyond_axis(%arg0: tensor<8x8xf32>, %arg1: ten
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=2>
+sdy.mesh @mesh = <["a"=8, "b"=2]>
 
 func.func @sub_axis_size_equals_full_size(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{sub-axis size is equal to the full axis size: "a":(1)8}}
@@ -399,7 +399,7 @@ func.func @sub_axis_size_equals_full_size(%arg0: tensor<8x8xf32>, %arg1: tensor<
 
 // -----
 
-sdy.mesh @mesh = <"a"=8, "b"=4>
+sdy.mesh @mesh = <["a"=8, "b"=4]>
 
 func.func @sub_axes_overlap(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> tensor<8x8xf32> {
   // expected-error @+1 {{overlapping sub-axes: "a":(1)4, "a":(2)4}}
@@ -409,7 +409,7 @@ func.func @sub_axes_overlap(%arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32>) -> t
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 func.func @sharding_bound_manual_computation(%arg0: tensor<16x32xf32>) -> tensor<16x32xf32> {
   %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"a",?}, {?}]>] out_shardings=[<@mesh, [{"a",?}, {?}]>] manual_axes={"a"} (%arg1: tensor<8x32xf32>) { // expected-note  {{parent bounding this axis as manual}}
diff --git a/shardy/dialect/sdy/transforms/export/test/sharding_constraint_to_reshard.mlir b/shardy/dialect/sdy/transforms/export/test/sharding_constraint_to_reshard.mlir
index 4f15c33..79e44bf 100644
--- a/shardy/dialect/sdy/transforms/export/test/sharding_constraint_to_reshard.mlir
+++ b/shardy/dialect/sdy/transforms/export/test/sharding_constraint_to_reshard.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -sdy-sharding-constraint-to-reshard | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 // CHECK-LABEL: func @sharding_constraint_to_reshard
 func.func @sharding_constraint_to_reshard(%arg0: tensor<8x8xf32>) -> tensor<8x8xf32> {
diff --git a/shardy/dialect/sdy/transforms/export/test/sink_data_flow_edges.mlir b/shardy/dialect/sdy/transforms/export/test/sink_data_flow_edges.mlir
index ba327f4..194b28b 100644
--- a/shardy/dialect/sdy/transforms/export/test/sink_data_flow_edges.mlir
+++ b/shardy/dialect/sdy/transforms/export/test/sink_data_flow_edges.mlir
@@ -1,7 +1,7 @@
 // RUN: sdy_opt %s -sdy-sink-data-flow-edges | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
-sdy.mesh @other_mesh = <"c"=4>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
+sdy.mesh @other_mesh = <["c"=4]>
 
 // TODO(tomnatan): once ops like while are allowed to have shardings with
 // different meshes, add a test that verifies that the first mesh name is used
diff --git a/shardy/dialect/sdy/transforms/export/test/update_non_divisible_input_output_shardings.mlir b/shardy/dialect/sdy/transforms/export/test/update_non_divisible_input_output_shardings.mlir
index c39d9f8..729762e 100644
--- a/shardy/dialect/sdy/transforms/export/test/update_non_divisible_input_output_shardings.mlir
+++ b/shardy/dialect/sdy/transforms/export/test/update_non_divisible_input_output_shardings.mlir
@@ -1,9 +1,9 @@
 // RUN: sdy_opt %s -sdy-update-non-divisible-input-output-shardings | FileCheck %s
 
-sdy.mesh @mesh_x_4_y_2 = <"x"=4, "y"=2>
-sdy.mesh @mesh_x_8_y_3 = <"x"=8, "y"=3>
-sdy.mesh @mesh_x_16 = <"x"=16>
-sdy.mesh @mesh_x_24 = <"x"=24>
+sdy.mesh @mesh_x_4_y_2 = <["x"=4, "y"=2]>
+sdy.mesh @mesh_x_8_y_3 = <["x"=8, "y"=3]>
+sdy.mesh @mesh_x_16 = <["x"=16]>
+sdy.mesh @mesh_x_24 = <["x"=24]>
 
 // CHECK-LABEL: func @only_one_dim_modified
 // CHECK-SAME:    %arg0: tensor<2x2xf32> {sdy.sharding = #sdy.sharding<@mesh_x_4_y_2, [{"x":(1)2}, {"y"}]>}
diff --git a/shardy/dialect/sdy/transforms/import/test/add_data_flow_edges.mlir b/shardy/dialect/sdy/transforms/import/test/add_data_flow_edges.mlir
index 67cede6..97c4c4f 100644
--- a/shardy/dialect/sdy/transforms/import/test/add_data_flow_edges.mlir
+++ b/shardy/dialect/sdy/transforms/import/test/add_data_flow_edges.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -sdy-add-data-flow-edges | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 // CHECK-LABEL: func @case
 func.func @case(%arg0: tensor<i32>, %arg1: tensor<8xi64>, %arg2: tensor<8xi64>,
diff --git a/shardy/dialect/sdy/transforms/import/test/apply_sharding_constraints.mlir b/shardy/dialect/sdy/transforms/import/test/apply_sharding_constraints.mlir
index 8e32d7c..c90f459 100644
--- a/shardy/dialect/sdy/transforms/import/test/apply_sharding_constraints.mlir
+++ b/shardy/dialect/sdy/transforms/import/test/apply_sharding_constraints.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -sdy-apply-sharding-constraints | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 // CHECK-LABEL: func @input_already_has_sharding
 func.func @input_already_has_sharding(%arg0: tensor<8x8xf32>) -> tensor<8x8xf32> {
diff --git a/shardy/dialect/sdy/transforms/import/test/import_pipeline.mlir b/shardy/dialect/sdy/transforms/import/test/import_pipeline.mlir
index 86fca6b..b74f6ad 100644
--- a/shardy/dialect/sdy/transforms/import/test/import_pipeline.mlir
+++ b/shardy/dialect/sdy/transforms/import/test/import_pipeline.mlir
@@ -23,7 +23,7 @@ func.func private @add_matmul_to_lhs(%arg0: tensor<8x16xf32>, %arg1: tensor<16x1
 
 // -----
 
-sdy.mesh @mesh = <"a"=2>
+sdy.mesh @mesh = <["a"=2]>
 
 // Verifies that `-apply-sharding-constraints` pass is applied after
 // `-add-data_flow_edges` pass
diff --git a/shardy/dialect/sdy/transforms/propagation/sharding_projection_test.cc b/shardy/dialect/sdy/transforms/propagation/sharding_projection_test.cc
index 0d1f311..a859066 100644
--- a/shardy/dialect/sdy/transforms/propagation/sharding_projection_test.cc
+++ b/shardy/dialect/sdy/transforms/propagation/sharding_projection_test.cc
@@ -113,7 +113,7 @@ class ShardingProjectionBuildTest : public PropagationTestBase {};
 
 TEST_F(ShardingProjectionBuildTest, DotGeneralSimple) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=4, "b"=2, "c"=2, "d"=2, "e"=2>
+    sdy.mesh @mesh = <["a"=4, "b"=2, "c"=2, "d"=2, "e"=2]>
 
     func.func @main(%arg0: tensor<2x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"b"}, {"a", ?}]>},
                     %arg1: tensor<8x4xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", "c"}, {"d", ?}], replicated={"b"}>})
@@ -163,7 +163,7 @@ TEST_F(ShardingProjectionBuildTest, DotGeneralSimple) {
 
 TEST_F(ShardingProjectionBuildTest, ReshapeSplitDim) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=4, "b"=2, "c"=3>
+    sdy.mesh @mesh = <["a"=4, "b"=2, "c"=3]>
 
     func.func @main(%arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", "b"}], replicated={"c"}>})
         -> tensor<2x4xf32> {
@@ -199,7 +199,7 @@ TEST_F(ShardingProjectionBuildTest, ReshapeSplitDim) {
 
 TEST_F(ShardingProjectionBuildTest, ReshapeSplitDimAxisAlreadySplit) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=16, "b"=8, "c"=4>
+    sdy.mesh @mesh = <["a"=16, "b"=8, "c"=4]>
 
     func.func @main(%arg0: tensor<16x8xf32>
         {sdy.sharding = #sdy.sharding<@mesh, [{"a":(1)2, "b"}, {"a":(2)8}], replicated={"c":(2)2}>})
@@ -231,7 +231,7 @@ TEST_F(ShardingProjectionBuildTest, ReshapeSplitDimAxisAlreadySplit) {
 
 TEST_F(ShardingProjectionBuildTest, ReshapeMergeDim) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=2, "b"=2>
+    sdy.mesh @mesh = <["a"=2, "b"=2]>
 
     func.func @main(%arg0: tensor<4x4xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b"}]>})
         -> tensor<16xf32> {
@@ -262,7 +262,7 @@ TEST_F(ShardingProjectionBuildTest, ReshapeMergeDim) {
 
 TEST_F(ShardingProjectionBuildTest, ReshapeWithSizeOneDims) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=2>
+    sdy.mesh @mesh = <["a"=2]>
 
     func.func @main(%arg0: tensor<4x2x1xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}, {}, {}]>})
         -> tensor<8xf32> {
@@ -288,7 +288,7 @@ TEST_F(ShardingProjectionBuildTest, ReshapeWithSizeOneDims) {
 
 TEST_F(ShardingProjectionBuildTest, AddSingleFactorNonDivisible) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=3>
+    sdy.mesh @mesh = <["a"=3]>
 
     func.func @main(%arg0: tensor<2x4xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"a"}]>},
                     %arg1: tensor<2x4xf32>)
@@ -314,7 +314,7 @@ TEST_F(ShardingProjectionBuildTest, AddSingleFactorNonDivisible) {
 
 TEST_F(ShardingProjectionBuildTest, SingleFactorOverflows) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=2, "b"=4>
+    sdy.mesh @mesh = <["a"=2, "b"=4]>
 
     func.func @main(%arg0: tensor<2x4xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"a", "b"}]>},
                     %arg1: tensor<2x4xf32>)
@@ -340,7 +340,7 @@ TEST_F(ShardingProjectionBuildTest, SingleFactorOverflows) {
 
 TEST_F(ShardingProjectionBuildTest, FactorWithSmallerSizeThanDimOverflows) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=2, "b"=4, "c"=2, "d"=4, "e"=2>
+    sdy.mesh @mesh = <["a"=2, "b"=4, "c"=2, "d"=4, "e"=2]>
 
     func.func @main(%arg0: tensor<32x4x16xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"c", ?}, {"b", "d":(2)2, "e"}]>})
         -> tensor<32x1x2xf32> {
@@ -371,7 +371,7 @@ TEST_F(ShardingProjectionBuildTest, FactorWithSmallerSizeThanDimOverflows) {
 
 TEST_F(ShardingProjectionBuildTest, ReshapeMinorMostFactorNonDivisible) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=6>
+    sdy.mesh @mesh = <["a"=6]>
 
     func.func @main(%arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}]>})
         -> tensor<2x4xf32> {
@@ -397,7 +397,7 @@ TEST_F(ShardingProjectionBuildTest, ReshapeMinorMostFactorNonDivisible) {
 
 TEST_F(ShardingProjectionBuildTest, ReshapeMinorMostFactorOverflows) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=16>
+    sdy.mesh @mesh = <["a"=16]>
 
     func.func @main(%arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}]>})
         -> tensor<2x4xf32> {
@@ -424,7 +424,7 @@ TEST_F(ShardingProjectionBuildTest, ReshapeMinorMostFactorOverflows) {
 TEST_F(ShardingProjectionBuildTest,
        ReshapeMinorMostFactorOverflowsSizeOneAxes) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=16, "b"=1, "c"=1>
+    sdy.mesh @mesh = <["a"=16, "b"=1, "c"=1]>
 
     func.func @main(%arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", "b", "c"}]>})
         -> tensor<2x4xf32> {
@@ -451,7 +451,7 @@ TEST_F(ShardingProjectionBuildTest,
 
 TEST_F(ShardingProjectionBuildTest, ReshapeNonMinorMostFactorNonDivisible) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=3>
+    sdy.mesh @mesh = <["a"=3]>
 
     func.func @main(%arg0: tensor<16xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}]>})
         -> tensor<4x4xf32> {
@@ -478,7 +478,7 @@ TEST_F(ShardingProjectionBuildTest, ReshapeNonMinorMostFactorNonDivisible) {
 TEST_F(ShardingProjectionBuildTest,
        ReshapeNonMinorMostFactorNonDivisibleSubAxis) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=6>
+    sdy.mesh @mesh = <["a"=6]>
 
     func.func @main(%arg0: tensor<16xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}]>})
         -> tensor<4x4xf32> {
@@ -505,7 +505,7 @@ TEST_F(ShardingProjectionBuildTest,
 TEST_F(ShardingProjectionBuildTest,
        ReshapeNonMinorMostFactorNonDivisibleMultipleAxes) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=2, "b"=3>
+    sdy.mesh @mesh = <["a"=2, "b"=3]>
 
     func.func @main(%arg0: tensor<16xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", "b"}]>})
         -> tensor<4x4xf32> {
@@ -531,7 +531,7 @@ TEST_F(ShardingProjectionBuildTest,
 
 TEST_F(ShardingProjectionBuildTest, ReshapeMinorMostFactorSizeOneAxes) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=1, "b"=2, "c"=1>
+    sdy.mesh @mesh = <["a"=1, "b"=2, "c"=1]>
 
     func.func @main(%arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", "b", "c"}]>})
         -> tensor<2x4xf32> {
@@ -563,7 +563,7 @@ class ShardingProjectionUpdateShardingTest : public PropagationTestBase {};
 
 TEST_F(ShardingProjectionUpdateShardingTest, DotGeneralSimple) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=4, "b"=4, "c"=4, "d"=4, "e"=4, "f"=4>
+    sdy.mesh @mesh = <["a"=4, "b"=4, "c"=4, "d"=4, "e"=4, "f"=4]>
 
     func.func @main(%arg0: tensor<256x512xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", "b"}, {"c", ?}]>},
                     %arg1: tensor<512x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"e"}, {"d", ?}], replicated={"f":(2)2}>})
@@ -701,7 +701,7 @@ class CreateTensorShardingAttrTest : public PropagationTestBase {
 
 TEST_F(CreateTensorShardingAttrTest, ConsecutiveSubAxesMerged) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=8, "b"=2, "c"=2>
+    sdy.mesh @mesh = <["a"=8, "b"=2, "c"=2]>
 
     func.func @main(%arg0: tensor<4x4xf32>) -> tensor<16xf32> {
       %0 = stablehlo.reshape %arg0 : (tensor<4x4xf32>) -> tensor<16xf32>
@@ -732,7 +732,7 @@ TEST_F(CreateTensorShardingAttrTest, ConsecutiveSubAxesMerged) {
 
 TEST_F(CreateTensorShardingAttrTest, OverflowSubAxisMerged) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=6, "b"=2>
+    sdy.mesh @mesh = <["a"=6, "b"=2]>
 
     func.func @main(%arg0: tensor<8xf32>) -> tensor<2x4xf32> {
       %0 = stablehlo.reshape %arg0 : (tensor<8xf32>) -> tensor<2x4xf32>
@@ -763,7 +763,7 @@ TEST_F(CreateTensorShardingAttrTest, OverflowSubAxisMerged) {
 
 TEST_F(CreateTensorShardingAttrTest, NonMinorMostFactorFullySharded) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=2, "b"=2, "c"=4, "d"=2>
+    sdy.mesh @mesh = <["a"=2, "b"=2, "c"=4, "d"=2]>
 
     func.func @main(%arg0: tensor<4x4xf32>) -> tensor<16xf32> {
       %0 = stablehlo.reshape %arg0 : (tensor<4x4xf32>) -> tensor<16xf32>
@@ -795,7 +795,7 @@ TEST_F(CreateTensorShardingAttrTest, NonMinorMostFactorFullySharded) {
 
 TEST_F(CreateTensorShardingAttrTest, NonMinorMostFactorPartiallySharded) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=2, "b"=2>
+    sdy.mesh @mesh = <["a"=2, "b"=2]>
 
     func.func @main(%arg0: tensor<4x4xf32>) -> tensor<16xf32> {
       %0 = stablehlo.reshape %arg0 : (tensor<4x4xf32>) -> tensor<16xf32>
@@ -823,7 +823,7 @@ TEST_F(CreateTensorShardingAttrTest, NonMinorMostFactorPartiallySharded) {
 
 TEST_F(CreateTensorShardingAttrTest, MinorMostFactorNotDivisible) {
   const std::string program = R"mlir(
-    sdy.mesh @mesh = <"a"=3, "b"=4>
+    sdy.mesh @mesh = <["a"=3, "b"=4]>
 
     func.func @main(%arg0: tensor<4x4xf32>) -> tensor<16xf32> {
       %0 = stablehlo.reshape %arg0 : (tensor<4x4xf32>) -> tensor<16xf32>
diff --git a/shardy/dialect/sdy/transforms/propagation/test/aggressive_propagation.mlir b/shardy/dialect/sdy/transforms/propagation/test/aggressive_propagation.mlir
index 22ef473..f482ce4 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/aggressive_propagation.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/aggressive_propagation.mlir
@@ -1,7 +1,7 @@
 // RUN: sdy_opt %s -sdy-aggressive-propagate="propagation-strategy=aggressive" -verify-diagnostics 2>&1 | FileCheck %s
 
-sdy.mesh @mesh_a_2_b_2 = <"a"=2, "b"=2>
-sdy.mesh @mesh_a_2_b_2_c_2 = <"a"=2, "b"=2, "c"=2>
+sdy.mesh @mesh_a_2_b_2 = <["a"=2, "b"=2]>
+sdy.mesh @mesh_a_2_b_2_c_2 = <["a"=2, "b"=2, "c"=2]>
 
 // CHECK-LABEL: func @no_conflict(
 // CHECK-SAME:      %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a"}, {"b"}]>},
diff --git a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation.mlir b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation.mlir
index 84d67e5..ef6ecfa 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation.mlir
@@ -1,21 +1,21 @@
 // RUN: sdy_opt %s -sdy-basic-propagate -verify-diagnostics 2>&1 | FileCheck %s
 
-sdy.mesh @mesh_a_3 = <"a"=3>
-sdy.mesh @mesh_a_6 = <"a"=6>
-sdy.mesh @mesh_a_2_b_2 = <"a"=2, "b"=2>
-sdy.mesh @mesh_a_2_b_3 = <"a"=2, "b"=3>
-sdy.mesh @mesh_a_3_b_3 = <"a"=3, "b"=3>
-sdy.mesh @mesh_a_4_b_2 = <"a"=4, "b"=2>
-sdy.mesh @mesh_a_4_b_4 = <"a"=4, "b"=4>
-sdy.mesh @mesh_a_6_b_2 = <"a"=6, "b"=2>
-sdy.mesh @mesh_a_16_b_2 = <"a"=16, "b"=2>
-sdy.mesh @mesh_a_1_b_2_c_1 = <"a"=1, "b"=2, "c"=1>
-sdy.mesh @mesh_a_1_b_2_c_1_d_2 = <"a"=1, "b"=2, "c"=1, "d"=2>
-sdy.mesh @mesh_a_2_b_2_c_2 = <"a"=2, "b"=2, "c"=2>
-sdy.mesh @mesh_a_4_b_2_c_2 = <"a"=4, "b"=2, "c"=2>
-sdy.mesh @mesh_a_2_b_3_c_2 = <"a"=2, "b"=3, "c"=2>
-sdy.mesh @mesh_a_2_b_3_c_2_d_2 = <"a"=2, "b"=3, "c"=2, "d"=2>
-sdy.mesh @mesh_a_3_another = <"a"=3>
+sdy.mesh @mesh_a_3 = <["a"=3]>
+sdy.mesh @mesh_a_6 = <["a"=6]>
+sdy.mesh @mesh_a_2_b_2 = <["a"=2, "b"=2]>
+sdy.mesh @mesh_a_2_b_3 = <["a"=2, "b"=3]>
+sdy.mesh @mesh_a_3_b_3 = <["a"=3, "b"=3]>
+sdy.mesh @mesh_a_4_b_2 = <["a"=4, "b"=2]>
+sdy.mesh @mesh_a_4_b_4 = <["a"=4, "b"=4]>
+sdy.mesh @mesh_a_6_b_2 = <["a"=6, "b"=2]>
+sdy.mesh @mesh_a_16_b_2 = <["a"=16, "b"=2]>
+sdy.mesh @mesh_a_1_b_2_c_1 = <["a"=1, "b"=2, "c"=1]>
+sdy.mesh @mesh_a_1_b_2_c_1_d_2 = <["a"=1, "b"=2, "c"=1, "d"=2]>
+sdy.mesh @mesh_a_2_b_2_c_2 = <["a"=2, "b"=2, "c"=2]>
+sdy.mesh @mesh_a_4_b_2_c_2 = <["a"=4, "b"=2, "c"=2]>
+sdy.mesh @mesh_a_2_b_3_c_2 = <["a"=2, "b"=3, "c"=2]>
+sdy.mesh @mesh_a_2_b_3_c_2_d_2 = <["a"=2, "b"=3, "c"=2, "d"=2]>
+sdy.mesh @mesh_a_3_another = <["a"=3]>
 
 // CHECK-LABEL: func @simple(
 // CHECK-SAME:      %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a"}, {"b"}]>},
diff --git a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_conservative.mlir b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_conservative.mlir
index 5ab02f4..c3fd632 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_conservative.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_conservative.mlir
@@ -1,8 +1,8 @@
 // RUN: sdy_opt %s -sdy-basic-propagate="conservative-propagation=true" 2>&1 | FileCheck %s
 
-sdy.mesh @mesh_a_4_b_2 = <"a"=4, "b"=2>
-sdy.mesh @mesh_a_2_b_8 = <"a"=2, "b"=8>
-sdy.mesh @mesh_a_16_b_2 = <"a"=16, "b"=2>
+sdy.mesh @mesh_a_4_b_2 = <["a"=4, "b"=2]>
+sdy.mesh @mesh_a_2_b_8 = <["a"=2, "b"=8]>
+sdy.mesh @mesh_a_16_b_2 = <["a"=16, "b"=2]>
 
 // CHECK-LABEL: func @reshape_split_dim
 func.func @reshape_split_dim(%arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_4_b_2, [{"a"}]>}) -> tensor<2x4xf32> {
diff --git a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_data_flow_edges.mlir b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_data_flow_edges.mlir
index 510635a..760e931 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_data_flow_edges.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_data_flow_edges.mlir
@@ -2,8 +2,8 @@
 
 // Propagation tests for ops with data-flow edges like CaseOp and WhileOp
 
-sdy.mesh @mesh_a_2_b_2 = <"a"=2, "b"=2>
-sdy.mesh @mesh_a_2_b_2_c_2 = <"a"=2, "b"=2, "c"=2>
+sdy.mesh @mesh_a_2_b_2 = <["a"=2, "b"=2]>
+sdy.mesh @mesh_a_2_b_2_c_2 = <["a"=2, "b"=2, "c"=2]>
 
 // CHECK-LABEL: func @case_single_result_func_args_single_sharding(
 // CHECK-SAME:      %arg0: tensor<i32>,
diff --git a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_keep_sharding_rules.mlir b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_keep_sharding_rules.mlir
index 5e961dd..e32cba2 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_keep_sharding_rules.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_keep_sharding_rules.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -sdy-basic-propagate='keep-sharding-rules=true' 2>&1 | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 // CHECK-LABEL: func @existing_and_created_rules_remain
 func.func @existing_and_created_rules_remain(%arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}, {"b"}]>},
diff --git a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_manual_computation.mlir b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_manual_computation.mlir
index f0e0e7d..dea2ea9 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_manual_computation.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation_manual_computation.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -sdy-basic-propagate 2>&1 | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2, "c"=2, "d"=2, "e"=2, "f"=2, "g"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2, "c"=2, "d"=2, "e"=2, "f"=2, "g"=2]>
 
 // -----------------------------------------------------------------------------
 // Basic tests without manual axes
diff --git a/shardy/dialect/sdy/transforms/propagation/test/op_priority_propagation.mlir b/shardy/dialect/sdy/transforms/propagation/test/op_priority_propagation.mlir
index b67f131..c35b399 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/op_priority_propagation.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/op_priority_propagation.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -sdy-op-priority-propagate 2>&1 | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2]>
 
 // Without prioritizing element-wise ops first, the sharding on dim 0 would
 // have been propagated first.
diff --git a/shardy/dialect/sdy/transforms/propagation/test/propagation_pipeline.mlir b/shardy/dialect/sdy/transforms/propagation/test/propagation_pipeline.mlir
index 85bcb55..4a51bd9 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/propagation_pipeline.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/propagation_pipeline.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -sdy-propagation-pipeline 2>&1 | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2, "c"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2, "c"=2]>
 
 // CHECK-LABEL: func @split_constants_different_sharding
 func.func @split_constants_different_sharding(
diff --git a/shardy/dialect/sdy/transforms/propagation/test/propagation_pipeline_data_flow_edges.mlir b/shardy/dialect/sdy/transforms/propagation/test/propagation_pipeline_data_flow_edges.mlir
index cee8fea..ad273f6 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/propagation_pipeline_data_flow_edges.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/propagation_pipeline_data_flow_edges.mlir
@@ -2,8 +2,8 @@
 
 // Propagation tests for ops with data-flow edges like CaseOp and WhileOp
 
-sdy.mesh @mesh_a_2_b_2 = <"a"=2, "b"=2>
-sdy.mesh @mesh_a_2_b_2_c_2 = <"a"=2, "b"=2, "c"=2>
+sdy.mesh @mesh_a_2_b_2 = <["a"=2, "b"=2]>
+sdy.mesh @mesh_a_2_b_2_c_2 = <["a"=2, "b"=2, "c"=2]>
 
 // CHECK-LABEL: func @case_single_result_func_args_single_sharding(
 // CHECK-SAME:      %arg0: tensor<i32>,
diff --git a/shardy/dialect/sdy/transforms/propagation/test/user_priority_propagation.mlir b/shardy/dialect/sdy/transforms/propagation/test/user_priority_propagation.mlir
index d0e375e..3a1b98f 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/user_priority_propagation.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/user_priority_propagation.mlir
@@ -1,6 +1,6 @@
 // RUN: sdy_opt %s -sdy-user-priority-propagate 2>&1 | FileCheck %s
 
-sdy.mesh @mesh = <"a"=2, "b"=2, "c"=2>
+sdy.mesh @mesh = <["a"=2, "b"=2, "c"=2]>
 
 // CHECK-LABEL: func @no_priorities(
 // CHECK-SAME:      %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}, {"b"}]>},
